{"nbformat":4,"nbformat_minor":5,"metadata":{"language_info":{"name":"python"},"kernelspec":{"name":"synapse_pyspark","display_name":"Synapse PySpark"},"microsoft":{"language":"python","host":{"trident":{"lakehouse":{"known_lakehouses":"[{\"id\":\"892ea2f2-ba24-4c97-9708-4aee54aa5c3a\"}]","default_lakehouse":"892ea2f2-ba24-4c97-9708-4aee54aa5c3a"}}},"ms_spell_check":{"ms_spell_check_language":"en"}},"widgets":{},"kernel_info":{"name":"synapse_pyspark"},"nteract":{"version":"nteract-front-end@1.0.0"},"save_output":true,"spark_compute":{"compute_id":"/trident/default","session_options":{"enableDebugMode":false,"conf":{}}},"notebook_environment":{},"synapse_widget":{"version":"0.1","state":{}},"trident":{"lakehouse":{"default_lakehouse":"892ea2f2-ba24-4c97-9708-4aee54aa5c3a","known_lakehouses":[{"id":"892ea2f2-ba24-4c97-9708-4aee54aa5c3a"}],"default_lakehouse_name":"Silver","default_lakehouse_workspace_id":"502d5a7b-1acf-4ad8-8b70-01ead5cbd1d3"}}},"cells":[{"cell_type":"markdown","source":["# Imports"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"864c5e74-61bb-499e-83bd-5a466f5f9d09"},{"cell_type":"code","source":["import numpy as np\r\n","import pandas as pd\r\n","import mlflow\r\n","import mlflow.sklearn\r\n","from sklearn.ensemble import RandomForestRegressor\r\n","from sklearn.metrics import accuracy_score\r\n","from mlflow.models import infer_signature"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"dd692d29-346b-488c-bdc2-81dc22d19d50","statement_id":3,"state":"finished","livy_statement_state":"available","queued_time":"2023-08-04T09:16:08.310239Z","session_start_time":"2023-08-04T09:16:08.8073172Z","execution_start_time":"2023-08-04T09:16:19.0423535Z","execution_finish_time":"2023-08-04T09:16:27.3767152Z","spark_jobs":{"numbers":{"FAILED":0,"RUNNING":0,"UNKNOWN":0,"SUCCEEDED":0},"jobs":[],"limit":20,"rule":"ALL_DESC"},"parent_msg_id":"e89fe02c-87e7-4de2-9a29-7b76f4c15825"},"text/plain":"StatementMeta(, dd692d29-346b-488c-bdc2-81dc22d19d50, 3, Finished, Available)"},"metadata":{}}],"execution_count":1,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"07909a91-b5c8-43a7-b8ff-73f4cdf96728"},{"cell_type":"markdown","source":["# Load data"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"3c2046a8-cffd-47d6-8556-259989d50934"},{"cell_type":"code","source":["# Load test data\n","test = spark.sql(\"SELECT * FROM Silver.test\")\n","test.show(5)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"dd692d29-346b-488c-bdc2-81dc22d19d50","statement_id":4,"state":"finished","livy_statement_state":"available","queued_time":"2023-08-04T09:16:08.3107567Z","session_start_time":null,"execution_start_time":"2023-08-04T09:16:27.8787039Z","execution_finish_time":"2023-08-04T09:16:42.3709305Z","spark_jobs":{"numbers":{"FAILED":0,"RUNNING":0,"UNKNOWN":0,"SUCCEEDED":5},"jobs":[{"displayName":"showString at NativeMethodAccessorImpl.java:0","dataWritten":0,"dataRead":26926,"rowCount":1459,"usageDescription":"","jobId":12,"name":"showString at NativeMethodAccessorImpl.java:0","description":"Job group for statement 4:\n# Load test data\ntest = spark.sql(\"SELECT * FROM Silver.test\")\ntest.show(5)","submissionTime":"2023-08-04T09:16:41.185GMT","completionTime":"2023-08-04T09:16:41.373GMT","stageIds":[20],"jobGroup":"4","status":"SUCCEEDED","numTasks":1,"numActiveTasks":0,"numCompletedTasks":1,"numSkippedTasks":0,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":1,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":0,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"$anonfun$recordDeltaOperationInternal$1 at SynapseLoggingShim.scala:95","dataWritten":0,"dataRead":2385,"rowCount":5,"usageDescription":"","jobId":11,"name":"$anonfun$recordDeltaOperationInternal$1 at SynapseLoggingShim.scala:95","description":"Delta: Job group for statement 4:\n# Load test data\ntest = spark.sql(\"SELECT * FROM Silver.test\")\ntest.show(5): Filtering files for query","submissionTime":"2023-08-04T09:16:40.490GMT","completionTime":"2023-08-04T09:16:41.046GMT","stageIds":[19,18],"jobGroup":"4","status":"SUCCEEDED","numTasks":53,"numActiveTasks":0,"numCompletedTasks":50,"numSkippedTasks":3,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":50,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":1,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"toString at String.java:2994","dataWritten":0,"dataRead":4441,"rowCount":50,"usageDescription":"","jobId":10,"name":"toString at String.java:2994","description":"Delta: Job group for statement 4:\n# Load test data\ntest = spark.sql(\"SELECT * FROM Silver.test\")\ntest.show(5): Compute snapshot for version: 2","submissionTime":"2023-08-04T09:16:39.870GMT","completionTime":"2023-08-04T09:16:39.917GMT","stageIds":[15,16,17],"jobGroup":"4","status":"SUCCEEDED","numTasks":54,"numActiveTasks":0,"numCompletedTasks":1,"numSkippedTasks":53,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":1,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":2,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"toString at String.java:2994","dataWritten":4441,"dataRead":5233,"rowCount":60,"usageDescription":"","jobId":9,"name":"toString at String.java:2994","description":"Delta: Job group for statement 4:\n# Load test data\ntest = spark.sql(\"SELECT * FROM Silver.test\")\ntest.show(5): Compute snapshot for version: 2","submissionTime":"2023-08-04T09:16:38.938GMT","completionTime":"2023-08-04T09:16:39.844GMT","stageIds":[13,14],"jobGroup":"4","status":"SUCCEEDED","numTasks":53,"numActiveTasks":0,"numCompletedTasks":50,"numSkippedTasks":3,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":50,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":1,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"toString at String.java:2994","dataWritten":5233,"dataRead":4982,"rowCount":20,"usageDescription":"","jobId":8,"name":"toString at String.java:2994","description":"Delta: Job group for statement 4:\n# Load test data\ntest = spark.sql(\"SELECT * FROM Silver.test\")\ntest.show(5): Compute snapshot for version: 2","submissionTime":"2023-08-04T09:16:38.104GMT","completionTime":"2023-08-04T09:16:38.720GMT","stageIds":[12],"jobGroup":"4","status":"SUCCEEDED","numTasks":3,"numActiveTasks":0,"numCompletedTasks":3,"numSkippedTasks":0,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":3,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":0,"numFailedStages":0,"killedTasksSummary":{}}],"limit":20,"rule":"ALL_DESC"},"parent_msg_id":"faa80015-ac2e-43db-ac66-747238e6b592"},"text/plain":"StatementMeta(, dd692d29-346b-488c-bdc2-81dc22d19d50, 4, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["+-----------+---------+----------+----------+-----------+--------+--------+------------+---------+\n|OverallQual|GrLivArea|GarageCars|GarageArea|TotalBsmtSF|1stFlrSF|FullBath|TotRmsAbvGrd|YearBuilt|\n+-----------+---------+----------+----------+-----------+--------+--------+------------+---------+\n|          8|     1418|       3.0|     852.0|     1642.0|    1418|       1|           6|     2010|\n|          4|     1362|       3.0|     768.0|     1040.0|    1362|       1|           6|     1957|\n|          6|     1521|       3.0|     640.0|      741.0|     780|       1|           8|     1910|\n|          5|     1072|       5.0|    1184.0|     1072.0|    1072|       1|           5|     1925|\n|          9|     1680|       3.0|    1138.0|     1555.0|    1680|       1|           8|     2009|\n+-----------+---------+----------+----------+-----------+--------+--------+------------+---------+\nonly showing top 5 rows\n\n"]}],"execution_count":2,"metadata":{},"id":"cf406d61-8716-4bb4-9877-2c07caa6658b"},{"cell_type":"code","source":["# Load train data\r\n","train = spark.sql(\"SELECT * FROM Silver.train\")\r\n","train.show(5)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"dd692d29-346b-488c-bdc2-81dc22d19d50","statement_id":5,"state":"finished","livy_statement_state":"available","queued_time":"2023-08-04T09:16:08.3112198Z","session_start_time":null,"execution_start_time":"2023-08-04T09:16:42.8821123Z","execution_finish_time":"2023-08-04T09:16:46.6152867Z","spark_jobs":{"numbers":{"FAILED":0,"RUNNING":0,"UNKNOWN":0,"SUCCEEDED":5},"jobs":[{"displayName":"showString at NativeMethodAccessorImpl.java:0","dataWritten":0,"dataRead":32310,"rowCount":1458,"usageDescription":"","jobId":17,"name":"showString at NativeMethodAccessorImpl.java:0","description":"Job group for statement 5:\n# Load train data\ntrain = spark.sql(\"SELECT * FROM Silver.train\")\ntrain.show(5)","submissionTime":"2023-08-04T09:16:45.476GMT","completionTime":"2023-08-04T09:16:45.695GMT","stageIds":[29],"jobGroup":"5","status":"SUCCEEDED","numTasks":1,"numActiveTasks":0,"numCompletedTasks":1,"numSkippedTasks":0,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":1,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":0,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"$anonfun$recordDeltaOperationInternal$1 at SynapseLoggingShim.scala:95","dataWritten":0,"dataRead":2375,"rowCount":5,"usageDescription":"","jobId":16,"name":"$anonfun$recordDeltaOperationInternal$1 at SynapseLoggingShim.scala:95","description":"Delta: Job group for statement 5:\n# Load train data\ntrain = spark.sql(\"SELECT * FROM Silver.train\")\ntrain.show(5): Filtering files for query","submissionTime":"2023-08-04T09:16:44.972GMT","completionTime":"2023-08-04T09:16:45.367GMT","stageIds":[27,28],"jobGroup":"5","status":"SUCCEEDED","numTasks":53,"numActiveTasks":0,"numCompletedTasks":50,"numSkippedTasks":3,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":50,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":1,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"toString at String.java:2994","dataWritten":0,"dataRead":4428,"rowCount":50,"usageDescription":"","jobId":15,"name":"toString at String.java:2994","description":"Delta: Job group for statement 5:\n# Load train data\ntrain = spark.sql(\"SELECT * FROM Silver.train\")\ntrain.show(5): Compute snapshot for version: 2","submissionTime":"2023-08-04T09:16:44.606GMT","completionTime":"2023-08-04T09:16:44.722GMT","stageIds":[24,25,26],"jobGroup":"5","status":"SUCCEEDED","numTasks":54,"numActiveTasks":0,"numCompletedTasks":1,"numSkippedTasks":53,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":1,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":2,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"toString at String.java:2994","dataWritten":4428,"dataRead":5208,"rowCount":60,"usageDescription":"","jobId":14,"name":"toString at String.java:2994","description":"Delta: Job group for statement 5:\n# Load train data\ntrain = spark.sql(\"SELECT * FROM Silver.train\")\ntrain.show(5): Compute snapshot for version: 2","submissionTime":"2023-08-04T09:16:43.692GMT","completionTime":"2023-08-04T09:16:44.571GMT","stageIds":[22,23],"jobGroup":"5","status":"SUCCEEDED","numTasks":53,"numActiveTasks":0,"numCompletedTasks":50,"numSkippedTasks":3,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":50,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":1,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"toString at String.java:2994","dataWritten":5208,"dataRead":5188,"rowCount":20,"usageDescription":"","jobId":13,"name":"toString at String.java:2994","description":"Delta: Job group for statement 5:\n# Load train data\ntrain = spark.sql(\"SELECT * FROM Silver.train\")\ntrain.show(5): Compute snapshot for version: 2","submissionTime":"2023-08-04T09:16:43.452GMT","completionTime":"2023-08-04T09:16:43.542GMT","stageIds":[21],"jobGroup":"5","status":"SUCCEEDED","numTasks":3,"numActiveTasks":0,"numCompletedTasks":3,"numSkippedTasks":0,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":3,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":0,"numFailedStages":0,"killedTasksSummary":{}}],"limit":20,"rule":"ALL_DESC"},"parent_msg_id":"e12a8417-6223-4837-b605-b5725575ac38"},"text/plain":"StatementMeta(, dd692d29-346b-488c-bdc2-81dc22d19d50, 5, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["+---------+-----------+---------+----------+----------+-----------+--------+--------+------------+---------+\n|SalePrice|OverallQual|GrLivArea|GarageCars|GarageArea|TotalBsmtSF|1stFlrSF|FullBath|TotRmsAbvGrd|YearBuilt|\n+---------+-----------+---------+----------+----------+-----------+--------+--------+------------+---------+\n|   206300|          7|     1344|         4|       784|       1344|    1344|       2|           8|     1997|\n|   265979|          7|     2640|         4|       864|       1240|    1320|       1|           8|     1880|\n|   168000|          4|     1622|         4|      1356|       1249|    1622|       1|           7|     1961|\n|   123000|          4|      872|         4|       480|        858|     872|       1|           5|     1971|\n|   200000|          5|     2634|         4|       968|       1248|    1338|       2|          12|     1969|\n+---------+-----------+---------+----------+----------+-----------+--------+--------+------------+---------+\nonly showing top 5 rows\n\n"]}],"execution_count":3,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"953c1845-5311-4653-bf63-e0420cee5103"},{"cell_type":"code","source":["# Convert input data to pandas\r\n","train = train.toPandas()\r\n","test = test.toPandas()"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"dd692d29-346b-488c-bdc2-81dc22d19d50","statement_id":6,"state":"finished","livy_statement_state":"available","queued_time":"2023-08-04T09:16:08.3116648Z","session_start_time":null,"execution_start_time":"2023-08-04T09:16:47.0802886Z","execution_finish_time":"2023-08-04T09:16:48.6662007Z","spark_jobs":{"numbers":{"FAILED":0,"RUNNING":0,"UNKNOWN":0,"SUCCEEDED":4},"jobs":[{"displayName":"toPandas at /tmp/ipykernel_7972/38703825.py:3","dataWritten":0,"dataRead":24576,"rowCount":1459,"usageDescription":"","jobId":21,"name":"toPandas at /tmp/ipykernel_7972/38703825.py:3","description":"Job group for statement 6:\n# Convert input data to pandas\ntrain = train.toPandas()\ntest = test.toPandas()","submissionTime":"2023-08-04T09:16:48.298GMT","completionTime":"2023-08-04T09:16:48.479GMT","stageIds":[35],"jobGroup":"6","status":"SUCCEEDED","numTasks":1,"numActiveTasks":0,"numCompletedTasks":1,"numSkippedTasks":0,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":1,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":0,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"toPandas at /tmp/ipykernel_7972/38703825.py:3","dataWritten":0,"dataRead":2385,"rowCount":5,"usageDescription":"","jobId":20,"name":"toPandas at /tmp/ipykernel_7972/38703825.py:3","description":"Delta: Job group for statement 6:\n# Convert input data to pandas\ntrain = train.toPandas()\ntest = test.toPandas(): Filtering files for query","submissionTime":"2023-08-04T09:16:48.046GMT","completionTime":"2023-08-04T09:16:48.229GMT","stageIds":[33,34],"jobGroup":"6","status":"SUCCEEDED","numTasks":53,"numActiveTasks":0,"numCompletedTasks":50,"numSkippedTasks":3,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":50,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":1,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"toPandas at /tmp/ipykernel_7972/38703825.py:2","dataWritten":0,"dataRead":29594,"rowCount":1458,"usageDescription":"","jobId":19,"name":"toPandas at /tmp/ipykernel_7972/38703825.py:2","description":"Job group for statement 6:\n# Convert input data to pandas\ntrain = train.toPandas()\ntest = test.toPandas()","submissionTime":"2023-08-04T09:16:47.509GMT","completionTime":"2023-08-04T09:16:47.670GMT","stageIds":[32],"jobGroup":"6","status":"SUCCEEDED","numTasks":1,"numActiveTasks":0,"numCompletedTasks":1,"numSkippedTasks":0,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":1,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":0,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"toPandas at /tmp/ipykernel_7972/38703825.py:2","dataWritten":0,"dataRead":2375,"rowCount":5,"usageDescription":"","jobId":18,"name":"toPandas at /tmp/ipykernel_7972/38703825.py:2","description":"Delta: Job group for statement 6:\n# Convert input data to pandas\ntrain = train.toPandas()\ntest = test.toPandas(): Filtering files for query","submissionTime":"2023-08-04T09:16:47.213GMT","completionTime":"2023-08-04T09:16:47.392GMT","stageIds":[30,31],"jobGroup":"6","status":"SUCCEEDED","numTasks":53,"numActiveTasks":0,"numCompletedTasks":50,"numSkippedTasks":3,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":50,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":1,"numFailedStages":0,"killedTasksSummary":{}}],"limit":20,"rule":"ALL_DESC"},"parent_msg_id":"ce7cddc7-bec9-4447-9f5f-4c684191b5e6"},"text/plain":"StatementMeta(, dd692d29-346b-488c-bdc2-81dc22d19d50, 6, Finished, Available)"},"metadata":{}}],"execution_count":4,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"fb2cc97d-2357-433c-baae-ae14b04a65e3"},{"cell_type":"code","source":["# Drop Na values for test data\r\n","test.dropna(how='any', inplace=True)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"dd692d29-346b-488c-bdc2-81dc22d19d50","statement_id":7,"state":"finished","livy_statement_state":"available","queued_time":"2023-08-04T09:16:08.3120881Z","session_start_time":null,"execution_start_time":"2023-08-04T09:16:49.155861Z","execution_finish_time":"2023-08-04T09:16:49.451727Z","spark_jobs":{"numbers":{"FAILED":0,"RUNNING":0,"UNKNOWN":0,"SUCCEEDED":0},"jobs":[],"limit":20,"rule":"ALL_DESC"},"parent_msg_id":"83ca231e-4933-46b2-9127-b8e7b01e45a1"},"text/plain":"StatementMeta(, dd692d29-346b-488c-bdc2-81dc22d19d50, 7, Finished, Available)"},"metadata":{}}],"execution_count":5,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"56116632-95a6-40c2-ad8a-c87579193f81"},{"cell_type":"markdown","source":["# Split - Train, Test data"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"49c9bc70-8e1e-44dc-9333-381225644c64"},{"cell_type":"code","source":["def split_dataset(dataset, test_ratio=0.30):\r\n","  test_indices = np.random.rand(len(dataset)) < test_ratio\r\n","  return dataset[~test_indices], dataset[test_indices]\r\n","\r\n","train_ds_pd, valid_ds_pd = split_dataset(train)\r\n","print(\"{} examples in training, {} examples in testing.\".format(\r\n","    len(train_ds_pd), len(valid_ds_pd)))"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"dd692d29-346b-488c-bdc2-81dc22d19d50","statement_id":8,"state":"finished","livy_statement_state":"available","queued_time":"2023-08-04T09:16:08.3125092Z","session_start_time":null,"execution_start_time":"2023-08-04T09:16:49.9618025Z","execution_finish_time":"2023-08-04T09:16:50.2741013Z","spark_jobs":{"numbers":{"FAILED":0,"RUNNING":0,"UNKNOWN":0,"SUCCEEDED":0},"jobs":[],"limit":20,"rule":"ALL_DESC"},"parent_msg_id":"4a136e77-2804-43ee-a49b-63df4e125bb0"},"text/plain":"StatementMeta(, dd692d29-346b-488c-bdc2-81dc22d19d50, 8, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["1017 examples in training, 441 examples in testing.\n"]}],"execution_count":6,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"8ba60c81-b6a8-4587-ad5e-2b198f256c2d"},{"cell_type":"code","source":["y_train = train.SalePrice.values\r\n","X_train = train.drop(['SalePrice'], axis=1)\r\n","y_test = valid_ds_pd.SalePrice.values\r\n","X_test = valid_ds_pd.drop(['SalePrice'], axis=1)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"dd692d29-346b-488c-bdc2-81dc22d19d50","statement_id":9,"state":"finished","livy_statement_state":"available","queued_time":"2023-08-04T09:16:08.312974Z","session_start_time":null,"execution_start_time":"2023-08-04T09:16:50.7927946Z","execution_finish_time":"2023-08-04T09:16:51.0857003Z","spark_jobs":{"numbers":{"FAILED":0,"RUNNING":0,"UNKNOWN":0,"SUCCEEDED":0},"jobs":[],"limit":20,"rule":"ALL_DESC"},"parent_msg_id":"61ddae43-fd69-4074-9efc-3a78180b466c"},"text/plain":"StatementMeta(, dd692d29-346b-488c-bdc2-81dc22d19d50, 9, Finished, Available)"},"metadata":{}}],"execution_count":7,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"d641feda-50fc-4bed-845e-b09e5dbf7b31"},{"cell_type":"markdown","source":["# Training"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"6ee8f99b-3606-4b4b-83ba-2fecf1f7cf7e"},{"cell_type":"code","source":["def train(X_train, X_test, y_train, y_test, max_detph, max_features, n_estimators):\r\n","    \"\"\"\r\n","    :X_train: training data\r\n","    :X_test: testing data\r\n","    :y_train: sale prices for training data\r\n","    :y_test: testing data\r\n","    :max_detph: int Max tree depth\r\n","    :max_features: float percentage of features to use in classification\r\n","    :n_estimators: int number of trees to create\r\n","    :return: Trained Model\r\n","    \"\"\"\r\n","    mod = RandomForestRegressor(\r\n","        max_depth=max_depth, max_features=max_features, n_estimators=n_estimators\r\n","    )\r\n","\r\n","    mod.fit(X_train, y_train)\r\n","    preds = mod.predict(X_test)\r\n","\r\n","    errors = abs(preds - y_test)\r\n","    MSE=round(np.mean(errors),2)\r\n","    MAPE=100*(errors/y_test)\r\n","    accuracy=round (100 - np.mean(MAPE),2)\r\n","    print(f'accuracy: {accuracy}')\r\n","\r\n","    output_table = X_test.copy()\r\n","    output_table['SalePRice'] = y_test\r\n","    output_table['PredictedPrice'] = preds\r\n","    output_table = spark.createDataFrame(output_table)\r\n","    output_table.write.format(\"delta\").mode('overwrite').save(\"abfss://HousingPrices@onelake.dfs.fabric.microsoft.com/Gold.Lakehouse/Tables/mlflow_rf_training\")\r\n","\r\n","    mlparams = {\r\n","        \"max_depth\": str(max_depth),\r\n","        \"max_features\": str(max_features),\r\n","        \"n_estimators\": str(n_estimators),\r\n","    }\r\n","    mlflow.log_params(mlparams)\r\n","\r\n","    mlmetrics = {\"accuracy\": accuracy, \"MSE\": MSE}\r\n","    mlflow.log_metrics(mlmetrics)\r\n","\r\n","    return mod, infer_signature(X_train, y_train)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"dd692d29-346b-488c-bdc2-81dc22d19d50","statement_id":10,"state":"finished","livy_statement_state":"available","queued_time":"2023-08-04T09:16:08.3238421Z","session_start_time":null,"execution_start_time":"2023-08-04T09:16:51.5634977Z","execution_finish_time":"2023-08-04T09:16:51.8837911Z","spark_jobs":{"numbers":{"FAILED":0,"RUNNING":0,"UNKNOWN":0,"SUCCEEDED":0},"jobs":[],"limit":20,"rule":"ALL_DESC"},"parent_msg_id":"5a46f017-0f06-4207-8a48-a44f99acb324"},"text/plain":"StatementMeta(, dd692d29-346b-488c-bdc2-81dc22d19d50, 10, Finished, Available)"},"metadata":{}}],"execution_count":8,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"54e67309-0d27-49f1-8b41-afdb9931ac97"},{"cell_type":"code","source":["max_depth = 300\r\n","# max_features{“sqrt”, “log2”, None}, int or float, default=1.0, The default of 1.0 is equivalent to bagged trees and more randomness can be achieved by setting smaller values, e.g. 0.3.\r\n","max_features = 1.0\r\n","n_estimators = 100\r\n","\r\n","experiment_name = \"HousingPricesExp\"\r\n","registered_model_name = f\"{experiment_name}-randomforestmodel\"\r\n","artifact_path = \"housing-price-artifact\"\r\n","\r\n","mlflow.set_experiment(experiment_name)\r\n","\r\n","with mlflow.start_run(run_name=\"MLFlowModel\") as run:\r\n","    model, signature = train(X_train, X_test, y_train, y_test, max_depth, max_features, n_estimators)\r\n","    \r\n","    mlflow.sklearn.log_model(\r\n","        model,\r\n","        signature=signature,\r\n","        artifact_path=artifact_path,\r\n","        registered_model_name=registered_model_name,\r\n","    )\r\n","\r\n","    artifact_uri = mlflow.get_artifact_uri(artifact_path=artifact_path)\r\n","    \r\n","print(artifact_uri)\r\n","    #test_prediction = model.predict(test)\r\n","    #output_table = test.copy()\r\n","    #output_table['PredictedPrice'] = test_prediction\r\n","    #output_table = spark.createDataFrame(output_table)\r\n","    #output_table.write.format(\"delta\").mode('overwrite').save(\"abfss://HousingPrices@onelake.dfs.fabric.microsoft.com/Gold.Lakehouse/Tables/mlflow_rf_prediction\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"dd692d29-346b-488c-bdc2-81dc22d19d50","statement_id":11,"state":"finished","livy_statement_state":"available","queued_time":"2023-08-04T09:16:08.3243983Z","session_start_time":null,"execution_start_time":"2023-08-04T09:16:52.3775837Z","execution_finish_time":"2023-08-04T09:17:18.1268148Z","spark_jobs":{"numbers":{"FAILED":0,"RUNNING":0,"UNKNOWN":0,"SUCCEEDED":9},"jobs":[{"displayName":"toString at String.java:2994","dataWritten":0,"dataRead":4457,"rowCount":50,"usageDescription":"","jobId":30,"name":"toString at String.java:2994","description":"Delta: Job group for statement 11:\nmax_depth = 300\n# max_features{“sqrt”, “log2”, None}, int or float, default=1.0, The default of 1.0 is equivalent to bagged trees and more randomness can be achieved by setting smaller values, e.g. 0.3.\nmax_features = 1.0\nn_estimators = 100\n\nexperiment_name = \"HousingPricesExp\"\nregistered_model_name = f\"{experiment_name}-randomforestmodel\"\nartifact_path = \"housing-price-artifact\"\n\nmlflow.set_experiment(experiment_name)\n\nwith mlflow.start_run(run_name=\"MLFlowModel\") as run:\n    model, signature = train(X_train, X_test, y_train, y_test, max_depth, max_features, n_estimators)\n    \n    mlflow.sklearn.log_model(\n        model,\n        signature=signature,\n        artifact_path=artifact_path,\n        registered_model_name=registered_model_name,\n    )\n\n    artifact_uri = mlflow.get_artifact_uri(artifact_path=artifact_path)\n    \nprint(artifact_uri)\n    #test_prediction = model.predict(test)\n    #output_table = test.copy()\n    #output_table['PredictedPrice'] = test_prediction\n    #output_table = spark.createDataFrame(...: Compute snapshot for version: 2","submissionTime":"2023-08-04T09:17:01.985GMT","completionTime":"2023-08-04T09:17:02.033GMT","stageIds":[51,52,50],"jobGroup":"11","status":"SUCCEEDED","numTasks":54,"numActiveTasks":0,"numCompletedTasks":1,"numSkippedTasks":53,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":1,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":2,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"toString at String.java:2994","dataWritten":4457,"dataRead":5100,"rowCount":60,"usageDescription":"","jobId":29,"name":"toString at String.java:2994","description":"Delta: Job group for statement 11:\nmax_depth = 300\n# max_features{“sqrt”, “log2”, None}, int or float, default=1.0, The default of 1.0 is equivalent to bagged trees and more randomness can be achieved by setting smaller values, e.g. 0.3.\nmax_features = 1.0\nn_estimators = 100\n\nexperiment_name = \"HousingPricesExp\"\nregistered_model_name = f\"{experiment_name}-randomforestmodel\"\nartifact_path = \"housing-price-artifact\"\n\nmlflow.set_experiment(experiment_name)\n\nwith mlflow.start_run(run_name=\"MLFlowModel\") as run:\n    model, signature = train(X_train, X_test, y_train, y_test, max_depth, max_features, n_estimators)\n    \n    mlflow.sklearn.log_model(\n        model,\n        signature=signature,\n        artifact_path=artifact_path,\n        registered_model_name=registered_model_name,\n    )\n\n    artifact_uri = mlflow.get_artifact_uri(artifact_path=artifact_path)\n    \nprint(artifact_uri)\n    #test_prediction = model.predict(test)\n    #output_table = test.copy()\n    #output_table['PredictedPrice'] = test_prediction\n    #output_table = spark.createDataFrame(...: Compute snapshot for version: 2","submissionTime":"2023-08-04T09:17:01.279GMT","completionTime":"2023-08-04T09:17:01.895GMT","stageIds":[48,49],"jobGroup":"11","status":"SUCCEEDED","numTasks":53,"numActiveTasks":0,"numCompletedTasks":50,"numSkippedTasks":3,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":50,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":1,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"toString at String.java:2994","dataWritten":5100,"dataRead":5495,"rowCount":20,"usageDescription":"","jobId":28,"name":"toString at String.java:2994","description":"Delta: Job group for statement 11:\nmax_depth = 300\n# max_features{“sqrt”, “log2”, None}, int or float, default=1.0, The default of 1.0 is equivalent to bagged trees and more randomness can be achieved by setting smaller values, e.g. 0.3.\nmax_features = 1.0\nn_estimators = 100\n\nexperiment_name = \"HousingPricesExp\"\nregistered_model_name = f\"{experiment_name}-randomforestmodel\"\nartifact_path = \"housing-price-artifact\"\n\nmlflow.set_experiment(experiment_name)\n\nwith mlflow.start_run(run_name=\"MLFlowModel\") as run:\n    model, signature = train(X_train, X_test, y_train, y_test, max_depth, max_features, n_estimators)\n    \n    mlflow.sklearn.log_model(\n        model,\n        signature=signature,\n        artifact_path=artifact_path,\n        registered_model_name=registered_model_name,\n    )\n\n    artifact_uri = mlflow.get_artifact_uri(artifact_path=artifact_path)\n    \nprint(artifact_uri)\n    #test_prediction = model.predict(test)\n    #output_table = test.copy()\n    #output_table['PredictedPrice'] = test_prediction\n    #output_table = spark.createDataFrame(...: Compute snapshot for version: 2","submissionTime":"2023-08-04T09:17:01.031GMT","completionTime":"2023-08-04T09:17:01.111GMT","stageIds":[47],"jobGroup":"11","status":"SUCCEEDED","numTasks":3,"numActiveTasks":0,"numCompletedTasks":3,"numSkippedTasks":0,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":3,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":0,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"$anonfun$recordDeltaOperationInternal$1 at SynapseLoggingShim.scala:95","dataWritten":0,"dataRead":2253,"rowCount":4,"usageDescription":"","jobId":27,"name":"$anonfun$recordDeltaOperationInternal$1 at SynapseLoggingShim.scala:95","description":"Job group for statement 11:\nmax_depth = 300\n# max_features{“sqrt”, “log2”, None}, int or float, default=1.0, The default of 1.0 is equivalent to bagged trees and more randomness can be achieved by setting smaller values, e.g. 0.3.\nmax_features = 1.0\nn_estimators = 100\n\nexperiment_name = \"HousingPricesExp\"\nregistered_model_name = f\"{experiment_name}-randomforestmodel\"\nartifact_path = \"housing-price-artifact\"\n\nmlflow.set_experiment(experiment_name)\n\nwith mlflow.start_run(run_name=\"MLFlowModel\") as run:\n    model, signature = train(X_train, X_test, y_train, y_test, max_depth, max_features, n_estimators)\n    \n    mlflow.sklearn.log_model(\n        model,\n        signature=signature,\n        artifact_path=artifact_path,\n        registered_model_name=registered_model_name,\n    )\n\n    artifact_uri = mlflow.get_artifact_uri(artifact_path=artifact_path)\n    \nprint(artifact_uri)\n    #test_prediction = model.predict(test)\n    #output_table = test.copy()\n    #output_table['PredictedPrice'] = test_prediction\n    #output_table = spark.createDataFrame(...","submissionTime":"2023-08-04T09:17:00.244GMT","completionTime":"2023-08-04T09:17:00.418GMT","stageIds":[45,46],"jobGroup":"11","status":"SUCCEEDED","numTasks":52,"numActiveTasks":0,"numCompletedTasks":50,"numSkippedTasks":2,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":50,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":1,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"save at NativeMethodAccessorImpl.java:0","dataWritten":18841,"dataRead":18279,"rowCount":882,"usageDescription":"","jobId":26,"name":"save at NativeMethodAccessorImpl.java:0","description":"Job group for statement 11:\nmax_depth = 300\n# max_features{“sqrt”, “log2”, None}, int or float, default=1.0, The default of 1.0 is equivalent to bagged trees and more randomness can be achieved by setting smaller values, e.g. 0.3.\nmax_features = 1.0\nn_estimators = 100\n\nexperiment_name = \"HousingPricesExp\"\nregistered_model_name = f\"{experiment_name}-randomforestmodel\"\nartifact_path = \"housing-price-artifact\"\n\nmlflow.set_experiment(experiment_name)\n\nwith mlflow.start_run(run_name=\"MLFlowModel\") as run:\n    model, signature = train(X_train, X_test, y_train, y_test, max_depth, max_features, n_estimators)\n    \n    mlflow.sklearn.log_model(\n        model,\n        signature=signature,\n        artifact_path=artifact_path,\n        registered_model_name=registered_model_name,\n    )\n\n    artifact_uri = mlflow.get_artifact_uri(artifact_path=artifact_path)\n    \nprint(artifact_uri)\n    #test_prediction = model.predict(test)\n    #output_table = test.copy()\n    #output_table['PredictedPrice'] = test_prediction\n    #output_table = spark.createDataFrame(...","submissionTime":"2023-08-04T09:16:59.596GMT","completionTime":"2023-08-04T09:17:00.113GMT","stageIds":[43,44],"jobGroup":"11","status":"SUCCEEDED","numTasks":9,"numActiveTasks":0,"numCompletedTasks":1,"numSkippedTasks":8,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":1,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":1,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"save at NativeMethodAccessorImpl.java:0","dataWritten":18279,"dataRead":0,"rowCount":441,"usageDescription":"","jobId":25,"name":"save at NativeMethodAccessorImpl.java:0","description":"Job group for statement 11:\nmax_depth = 300\n# max_features{“sqrt”, “log2”, None}, int or float, default=1.0, The default of 1.0 is equivalent to bagged trees and more randomness can be achieved by setting smaller values, e.g. 0.3.\nmax_features = 1.0\nn_estimators = 100\n\nexperiment_name = \"HousingPricesExp\"\nregistered_model_name = f\"{experiment_name}-randomforestmodel\"\nartifact_path = \"housing-price-artifact\"\n\nmlflow.set_experiment(experiment_name)\n\nwith mlflow.start_run(run_name=\"MLFlowModel\") as run:\n    model, signature = train(X_train, X_test, y_train, y_test, max_depth, max_features, n_estimators)\n    \n    mlflow.sklearn.log_model(\n        model,\n        signature=signature,\n        artifact_path=artifact_path,\n        registered_model_name=registered_model_name,\n    )\n\n    artifact_uri = mlflow.get_artifact_uri(artifact_path=artifact_path)\n    \nprint(artifact_uri)\n    #test_prediction = model.predict(test)\n    #output_table = test.copy()\n    #output_table['PredictedPrice'] = test_prediction\n    #output_table = spark.createDataFrame(...","submissionTime":"2023-08-04T09:16:59.497GMT","completionTime":"2023-08-04T09:16:59.554GMT","stageIds":[42],"jobGroup":"11","status":"SUCCEEDED","numTasks":8,"numActiveTasks":0,"numCompletedTasks":8,"numSkippedTasks":0,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":8,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":0,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"toString at String.java:2994","dataWritten":0,"dataRead":4452,"rowCount":50,"usageDescription":"","jobId":24,"name":"toString at String.java:2994","description":"Delta: Job group for statement 11:\nmax_depth = 300\n# max_features{“sqrt”, “log2”, None}, int or float, default=1.0, The default of 1.0 is equivalent to bagged trees and more randomness can be achieved by setting smaller values, e.g. 0.3.\nmax_features = 1.0\nn_estimators = 100\n\nexperiment_name = \"HousingPricesExp\"\nregistered_model_name = f\"{experiment_name}-randomforestmodel\"\nartifact_path = \"housing-price-artifact\"\n\nmlflow.set_experiment(experiment_name)\n\nwith mlflow.start_run(run_name=\"MLFlowModel\") as run:\n    model, signature = train(X_train, X_test, y_train, y_test, max_depth, max_features, n_estimators)\n    \n    mlflow.sklearn.log_model(\n        model,\n        signature=signature,\n        artifact_path=artifact_path,\n        registered_model_name=registered_model_name,\n    )\n\n    artifact_uri = mlflow.get_artifact_uri(artifact_path=artifact_path)\n    \nprint(artifact_uri)\n    #test_prediction = model.predict(test)\n    #output_table = test.copy()\n    #output_table['PredictedPrice'] = test_prediction\n    #output_table = spark.createDataFrame(...: Compute snapshot for version: 1","submissionTime":"2023-08-04T09:16:59.355GMT","completionTime":"2023-08-04T09:16:59.395GMT","stageIds":[39,40,41],"jobGroup":"11","status":"SUCCEEDED","numTasks":53,"numActiveTasks":0,"numCompletedTasks":1,"numSkippedTasks":52,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":1,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":2,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"toString at String.java:2994","dataWritten":4452,"dataRead":3424,"rowCount":57,"usageDescription":"","jobId":23,"name":"toString at String.java:2994","description":"Delta: Job group for statement 11:\nmax_depth = 300\n# max_features{“sqrt”, “log2”, None}, int or float, default=1.0, The default of 1.0 is equivalent to bagged trees and more randomness can be achieved by setting smaller values, e.g. 0.3.\nmax_features = 1.0\nn_estimators = 100\n\nexperiment_name = \"HousingPricesExp\"\nregistered_model_name = f\"{experiment_name}-randomforestmodel\"\nartifact_path = \"housing-price-artifact\"\n\nmlflow.set_experiment(experiment_name)\n\nwith mlflow.start_run(run_name=\"MLFlowModel\") as run:\n    model, signature = train(X_train, X_test, y_train, y_test, max_depth, max_features, n_estimators)\n    \n    mlflow.sklearn.log_model(\n        model,\n        signature=signature,\n        artifact_path=artifact_path,\n        registered_model_name=registered_model_name,\n    )\n\n    artifact_uri = mlflow.get_artifact_uri(artifact_path=artifact_path)\n    \nprint(artifact_uri)\n    #test_prediction = model.predict(test)\n    #output_table = test.copy()\n    #output_table['PredictedPrice'] = test_prediction\n    #output_table = spark.createDataFrame(...: Compute snapshot for version: 1","submissionTime":"2023-08-04T09:16:58.581GMT","completionTime":"2023-08-04T09:16:59.328GMT","stageIds":[37,38],"jobGroup":"11","status":"SUCCEEDED","numTasks":52,"numActiveTasks":0,"numCompletedTasks":50,"numSkippedTasks":2,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":50,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":1,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"toString at String.java:2994","dataWritten":3424,"dataRead":3963,"rowCount":14,"usageDescription":"","jobId":22,"name":"toString at String.java:2994","description":"Delta: Job group for statement 11:\nmax_depth = 300\n# max_features{“sqrt”, “log2”, None}, int or float, default=1.0, The default of 1.0 is equivalent to bagged trees and more randomness can be achieved by setting smaller values, e.g. 0.3.\nmax_features = 1.0\nn_estimators = 100\n\nexperiment_name = \"HousingPricesExp\"\nregistered_model_name = f\"{experiment_name}-randomforestmodel\"\nartifact_path = \"housing-price-artifact\"\n\nmlflow.set_experiment(experiment_name)\n\nwith mlflow.start_run(run_name=\"MLFlowModel\") as run:\n    model, signature = train(X_train, X_test, y_train, y_test, max_depth, max_features, n_estimators)\n    \n    mlflow.sklearn.log_model(\n        model,\n        signature=signature,\n        artifact_path=artifact_path,\n        registered_model_name=registered_model_name,\n    )\n\n    artifact_uri = mlflow.get_artifact_uri(artifact_path=artifact_path)\n    \nprint(artifact_uri)\n    #test_prediction = model.predict(test)\n    #output_table = test.copy()\n    #output_table['PredictedPrice'] = test_prediction\n    #output_table = spark.createDataFrame(...: Compute snapshot for version: 1","submissionTime":"2023-08-04T09:16:58.332GMT","completionTime":"2023-08-04T09:16:58.429GMT","stageIds":[36],"jobGroup":"11","status":"SUCCEEDED","numTasks":2,"numActiveTasks":0,"numCompletedTasks":2,"numSkippedTasks":0,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":2,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":0,"numFailedStages":0,"killedTasksSummary":{}}],"limit":20,"rule":"ALL_DESC"},"parent_msg_id":"e0ac2953-1e85-476b-b39d-2935edba92c4"},"text/plain":"StatementMeta(, dd692d29-346b-488c-bdc2-81dc22d19d50, 11, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["accuracy: 95.44\nsds://lake.trident.com/502d5a7b-1acf-4ad8-8b70-01ead5cbd1d3/3bbf8ea2-a690-47fe-a614-9513fc600e7a/63a3bec0-5d3f-4438-83cb-e81676c376a5/artifacts/housing-price-artifact\n"]},{"output_type":"stream","name":"stderr","text":["/opt/spark/python/lib/pyspark.zip/pyspark/sql/pandas/conversion.py:604: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n  [(c, t) for (_, c), t in zip(pdf_slice.iteritems(), arrow_types)]\n/home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages/mlflow/models/signature.py:130: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n  inputs = _infer_schema(model_input)\n/home/trusted-service-user/cluster-env/trident_env/lib/python3.10/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n  warnings.warn(\"Setuptools is replacing distutils.\")\nSuccessfully registered model 'HousingPricesExp-randomforestmodel'.\n2023/08/04 09:17:16 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: HousingPricesExp-randomforestmodel, version 5\nCreated version '5' of model 'HousingPricesExp-randomforestmodel'.\n"]}],"execution_count":9,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"224f1680-a754-4cf4-82d3-205a37996b4e"},{"cell_type":"code","source":["test_prediction = model.predict(test)\r\n","print(test_prediction.shape)\r\n","output_table = test.copy()\r\n","output_table['PredictedPrice'] = test_prediction\r\n","output_table = spark.createDataFrame(output_table)\r\n","output_table.write.format(\"delta\").mode('overwrite').save(\"abfss://HousingPrices@onelake.dfs.fabric.microsoft.com/Gold.Lakehouse/Tables/mlflow_rf_prediction\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"dd692d29-346b-488c-bdc2-81dc22d19d50","statement_id":13,"state":"finished","livy_statement_state":"available","queued_time":"2023-08-04T09:17:28.3856635Z","session_start_time":null,"execution_start_time":"2023-08-04T09:17:28.9003596Z","execution_finish_time":"2023-08-04T09:17:31.4431252Z","spark_jobs":{"numbers":{"FAILED":0,"RUNNING":0,"UNKNOWN":0,"SUCCEEDED":6},"jobs":[{"displayName":"toString at String.java:2994","dataWritten":0,"dataRead":4474,"rowCount":50,"usageDescription":"","jobId":45,"name":"toString at String.java:2994","description":"Delta: Job group for statement 13:\ntest_prediction = model.predict(test)\nprint(test_prediction.shape)\noutput_table = test.copy()\noutput_table['PredictedPrice'] = test_prediction\noutput_table = spark.createDataFrame(output_table)\noutput_table.write.format(\"delta\").mode('overwrite').save(\"abfss://HousingPrices@onelake.dfs.fabric.microsoft.com/Gold.Lakehouse/Tables/mlflow_rf_prediction\"): Compute snapshot for version: 4","submissionTime":"2023-08-04T09:17:30.849GMT","completionTime":"2023-08-04T09:17:30.875GMT","stageIds":[78,79,80],"jobGroup":"13","status":"SUCCEEDED","numTasks":56,"numActiveTasks":0,"numCompletedTasks":1,"numSkippedTasks":55,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":1,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":2,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"toString at String.java:2994","dataWritten":4474,"dataRead":8404,"rowCount":66,"usageDescription":"","jobId":44,"name":"toString at String.java:2994","description":"Delta: Job group for statement 13:\ntest_prediction = model.predict(test)\nprint(test_prediction.shape)\noutput_table = test.copy()\noutput_table['PredictedPrice'] = test_prediction\noutput_table = spark.createDataFrame(output_table)\noutput_table.write.format(\"delta\").mode('overwrite').save(\"abfss://HousingPrices@onelake.dfs.fabric.microsoft.com/Gold.Lakehouse/Tables/mlflow_rf_prediction\"): Compute snapshot for version: 4","submissionTime":"2023-08-04T09:17:30.397GMT","completionTime":"2023-08-04T09:17:30.833GMT","stageIds":[76,77],"jobGroup":"13","status":"SUCCEEDED","numTasks":55,"numActiveTasks":0,"numCompletedTasks":50,"numSkippedTasks":5,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":50,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":1,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"toString at String.java:2994","dataWritten":8404,"dataRead":8277,"rowCount":32,"usageDescription":"","jobId":43,"name":"toString at String.java:2994","description":"Delta: Job group for statement 13:\ntest_prediction = model.predict(test)\nprint(test_prediction.shape)\noutput_table = test.copy()\noutput_table['PredictedPrice'] = test_prediction\noutput_table = spark.createDataFrame(output_table)\noutput_table.write.format(\"delta\").mode('overwrite').save(\"abfss://HousingPrices@onelake.dfs.fabric.microsoft.com/Gold.Lakehouse/Tables/mlflow_rf_prediction\"): Compute snapshot for version: 4","submissionTime":"2023-08-04T09:17:30.082GMT","completionTime":"2023-08-04T09:17:30.180GMT","stageIds":[75],"jobGroup":"13","status":"SUCCEEDED","numTasks":5,"numActiveTasks":0,"numCompletedTasks":5,"numSkippedTasks":0,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":5,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":0,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"$anonfun$recordDeltaOperationInternal$1 at SynapseLoggingShim.scala:95","dataWritten":0,"dataRead":2648,"rowCount":6,"usageDescription":"","jobId":42,"name":"$anonfun$recordDeltaOperationInternal$1 at SynapseLoggingShim.scala:95","description":"Job group for statement 13:\ntest_prediction = model.predict(test)\nprint(test_prediction.shape)\noutput_table = test.copy()\noutput_table['PredictedPrice'] = test_prediction\noutput_table = spark.createDataFrame(output_table)\noutput_table.write.format(\"delta\").mode('overwrite').save(\"abfss://HousingPrices@onelake.dfs.fabric.microsoft.com/Gold.Lakehouse/Tables/mlflow_rf_prediction\")","submissionTime":"2023-08-04T09:17:29.428GMT","completionTime":"2023-08-04T09:17:29.579GMT","stageIds":[74,73],"jobGroup":"13","status":"SUCCEEDED","numTasks":54,"numActiveTasks":0,"numCompletedTasks":50,"numSkippedTasks":4,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":50,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":1,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"save at NativeMethodAccessorImpl.java:0","dataWritten":36430,"dataRead":48451,"rowCount":2914,"usageDescription":"","jobId":41,"name":"save at NativeMethodAccessorImpl.java:0","description":"Job group for statement 13:\ntest_prediction = model.predict(test)\nprint(test_prediction.shape)\noutput_table = test.copy()\noutput_table['PredictedPrice'] = test_prediction\noutput_table = spark.createDataFrame(output_table)\noutput_table.write.format(\"delta\").mode('overwrite').save(\"abfss://HousingPrices@onelake.dfs.fabric.microsoft.com/Gold.Lakehouse/Tables/mlflow_rf_prediction\")","submissionTime":"2023-08-04T09:17:29.057GMT","completionTime":"2023-08-04T09:17:29.339GMT","stageIds":[71,72],"jobGroup":"13","status":"SUCCEEDED","numTasks":9,"numActiveTasks":0,"numCompletedTasks":1,"numSkippedTasks":8,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":1,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":1,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"save at NativeMethodAccessorImpl.java:0","dataWritten":48451,"dataRead":0,"rowCount":1457,"usageDescription":"","jobId":40,"name":"save at NativeMethodAccessorImpl.java:0","description":"Job group for statement 13:\ntest_prediction = model.predict(test)\nprint(test_prediction.shape)\noutput_table = test.copy()\noutput_table['PredictedPrice'] = test_prediction\noutput_table = spark.createDataFrame(output_table)\noutput_table.write.format(\"delta\").mode('overwrite').save(\"abfss://HousingPrices@onelake.dfs.fabric.microsoft.com/Gold.Lakehouse/Tables/mlflow_rf_prediction\")","submissionTime":"2023-08-04T09:17:28.971GMT","completionTime":"2023-08-04T09:17:29.001GMT","stageIds":[70],"jobGroup":"13","status":"SUCCEEDED","numTasks":8,"numActiveTasks":0,"numCompletedTasks":8,"numSkippedTasks":0,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":8,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":0,"numFailedStages":0,"killedTasksSummary":{}}],"limit":20,"rule":"ALL_DESC"},"parent_msg_id":"ef9823a1-a18e-457e-9fba-22e8cbcfa448"},"text/plain":"StatementMeta(, dd692d29-346b-488c-bdc2-81dc22d19d50, 13, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["(1457,)\n"]},{"output_type":"stream","name":"stderr","text":["/opt/spark/python/lib/pyspark.zip/pyspark/sql/pandas/conversion.py:604: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n  [(c, t) for (_, c), t in zip(pdf_slice.iteritems(), arrow_types)]\n"]}],"execution_count":11,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"af8b2780-0be3-4715-b245-45878ad0ae58"},{"cell_type":"code","source":[],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"2c42d9b3-e32c-4daa-ae43-b4de23275c9d"}]}